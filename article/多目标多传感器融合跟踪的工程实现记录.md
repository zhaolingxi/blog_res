### 前言

最近接到个任务，用一个星期做一个云端多目标跟踪融合的小模块，顺便做一下开发原理的记录

------

### 理论部分（处理流程与步骤）

一个完整的融合与剔除流程通常包括以下几个步骤：

#### 步骤 1：数据预处理（时空对齐）

这是所有融合工作的基础。

1. **时间戳同步 (Time Synchronization)**：由于不同传感器的硬件延迟、数据传输和处理时间不同，它们上报数据的时间戳可能不一致。必须使用NTP、PTP等协议或者插值计算，将所有数据统一到一个共同的时间基准上。然后在融合的时候，用滑动时间窗口等待完成融合前同步。
2. **坐标系对齐 (Spatial Alignment)**：每个传感器都有自己的坐标系。需要将所有传感器的感知结果转换到同一个全局坐标系下（例如，车身中心坐标系、平面区域场地坐标系）。传感器外参标定需要提前确认。

#### 步骤 2：数据关联 (Data Association)

这一步是判断来自不同传感器的检测结果是否指向同一个真实世界中的目标。

- **输入**：来自所有传感器在同一坐标系下的目标列表（已经处理完成的时空帧）。

- **任务**：将描述同一目标的检测结果（`detections`）分组。

- 常用算法

  - **最近邻算法 (Nearest Neighbor, NN)**：将不同源的目标按空间距离（如欧氏距离）进行匹配，距离最近的为一组。这是一种简单但不够鲁棒的方法。（但是在实践中，它其实也足够简单可靠）
  - **全局最近邻 (Global Nearest Neighbor, GNN)**：寻找一个全局最优的匹配方案，使得所有匹配对的总距离最小。
  - **联合概率数据互联 (Joint Probabilistic Data Association, JPDA)**：一种更复杂的概率方法，它不做出硬性的“是或否”的关联决策，而是计算一个检测结果隶属于每个已有航迹的概率。

#### 步骤 3：状态估计与融合 (State Estimation and Fusion)

这是将关联到同一个目标的数据进行融合，得到一个更精确、更平滑的估计结果。这一步也是剔除算法发生作用的关键环节。

- 核心工具

  卡尔曼滤波器 (Kalman Filter, KF)及其变体。卡尔曼滤波器是一个“预测-更新”的循环过程，非常适合处理带噪声的传感器数据。

  - **预测 (Prediction)**：根据上一时刻的状态和运动模型，预测当前时刻目标可能在的位置。这个预测结果自身带有一个**不确定性**（协方差矩阵）。
  - **更新 (Update)**：用新的传感器观测值来修正预测值，得到一个更新后的状态估计，并减小其不确定性。

#### 步骤 4：异常检测与剔除算法

这正是您问题的核心。剔除操作主要发生在“更新”步骤之前，用于决定哪些观测值是“合格的”，可以用来更新我们的状态估计。

以下是一些主流的剔除算法：

1. **统计门控 (Statistical Gating)**

   - **原理**：在预测状态的周围创建一个“验证门”（Validation Gate）。这个门的大小由预测状态的不确定性和一个预设的门限共同决定。如果一个新的传感器观测值落在了这个门内，就认为它和预测是相关的；如果落在门外，则直接判定为异常值或不相关目标，不参与后续的融合。

   - **实现**：最常用的方法是基于**马氏距离 (Mahalanobis Distance)**。马氏距离考虑了状态预测的协方差（不确定性），它度量的是观测值与预测值之间的统计距离。我们可以将其与卡方分布 的某个分位数进行比较。若马氏距离的平方大于χ2*χ*2阈值，则拒绝该观测。

     

2. **几何门控 (Geometric Gating)**

   - **原理**：这种方法不依赖于运动学的状态向量（如速度、加速度）及其协方差，而是直接比较**预测的几何形状**与**观测的几何形状**之间的关系【例如 IoU】。在目标跟踪中，这通常指预测的边界框 (Bounding Box) 和检测到的边界框。
   - 实现 (IoU)：
     - **IoU (Intersection over Union)**：计算预测框与检测框的交集面积与并集面积之比。这个值域在 `[0, 1]` 之间，`1` 表示完美重合。
     - **门控/剔除**：设定一个 IoU 门限（例如 0.1）。如果一个检测框与某个航迹预测框的 IoU 值**低于**该门限，就认为它们不相关，直接剔除这次匹配可能。
     - **关联成本**：对于通过门控的候选者，通常使用 IoU 距离作为数据关联（如匈牙利算法）的成本。IoU 越高，距离越近，关联成本越低。

3. **卡方检验 (Chi-squared Test)**

   - **原理**：这是门控方法的数学基础。它专门用来检验“新息”（Innovation，即观测值与预测值之差）与“新息的协方差”之间的一致性。如果新息相对于其不确定性来说“过大”，那么统计上就可以认为这个观测值是一个小概率事件（即异常值）。
   - **应用**：在卡尔曼滤波的更新步骤中，计算新息及其协方差，然后进行χ2*χ*2检验。如果不通过检验，则**跳过此次更新**，或者**降低该观测值的权重**。这是一种在融合过程中动态剔除异常的有效手段。

4. **基于共识的算法 (Consensus-based Methods)**

   - **原理**：如果存在多个（例如≥3个）传感器观测，可以先比较它们之间的一致性。如果某个观测值与其他所有观测值都相去甚远，而其他观测值之间彼此靠近，那么这个“离群”的观测值很可能就是异常值。
   - **实现**：例如，可以两两计算观测值之间的距离，找到那个与其他所有观测值平均距离最大的一个，并将其剔除。RANSAC (Random Sample Consensus) 也是这类思想的代表。

5. **权重融合法 (Weighted Fusion)**

   - **原理**：与其硬性地“剔除”，不如给每个传感器观测分配一个置信度权重。置信度高的观测在融合结果中占比更大，置信度低的（可能是异常的）观测占比很小，从而被自然地“抑制”了。

   - 实现：权重可以根据多种信息来设定

     - **传感器自身的不确定性**：例如，雷达对距离的测量很准，但对角度的测量误差稍大。这可以反映在其协方差矩阵中，协方差越小，权重越高。
     - **历史表现**：持续跟踪一个传感器的准确率，如果它最近频繁产生异常数据，就动态降低它的权重。
     - **与预测的一致性**：与卡方检验类似，与预测偏差越大的观测，分配的权重越低。

6. **证据理论 (Dempster-Shafer Theory, DST)**

   - **原理**：这是一种比概率论更宽泛的不确定性推理框架。它可以很好地处理数据冲突的情况 [mdpi.com](https://www.mdpi.com/1424-8220/21/7/2542/pdf)。当不同传感器提供相互矛盾的信息时，DST能够量化这种“冲突”，而不是强制进行融合，从而避免“灾难性融合” [hindawi.com](https://www.hindawi.com/journals/aai/2013/241260/)。
   - **应用**：适用于需要明确区分“不确定”和“冲突”的场景，但计算复杂度较高。

------

### 案例：

我们现在要实现一个云端的传感器后融合与目标跟踪，已知有多个不同类型的传感器，每一个传感器有着不同的识别频率、不同的感知范围，同时每一个感知设备到达云端的延迟不一致，现需要完成感知目标的融合跟踪。

这是一个比较典型的工程问题，其主要的解决逻辑是在已经实现了基础的多目标跟踪算法之后，需要将算法落地到工程应用中。

我们主要的逻辑，应该是数据缓存->数据切片->帧内预处理->数据融合->轨迹预测匹配->轨迹跟踪->轨迹召回->结果输出

接下来我们给出一个相对完整的方案

### 实践方案

**具体实施步骤如下：**

1. **初始化**：

   - 维护一个动态的“航迹列表 (Track List)”，每个航迹代表一个被持续跟踪的目标。
   - 每个航迹包含其状态向量（如 `[x, y, vx, vy, width, length]`）如果使用统计方法的话，还需要协方差矩阵P（表示不确定性），如果选择多策略，需要加上置信度。

2. **循环执行 (在每个时间步)**：
   a. **接收数据**：获取所有传感器在当前帧上报的目标列表。
   b. **预处理**：主要需要做的事情是：1.数据缓存等待，2.数据坐标转换，3.数据时空对齐，4.不同数据源频率对齐（数据冗余删除）总之就是完成所有目标的时间和空间对齐，消除高频传感器的识别冗余。
   c. **预测**：遍历航迹列表中的每一个航迹，使用卡尔曼滤波器结合运动模型（如匀速、匀加速模型）预测其在当前时刻的状态和协方差。【在实现中，可以使用航迹分类，一般可以分为激活航迹、丢失航迹等】
   d. **更新、关联与剔除（这里我们选择bytetrack）**：
   \* 对于每一个航迹，遍历所有新的传感器观测值。
   \* 第一次关联 (高分检测框):

   - **计算成本**: 计算所有航迹的预测框与**高分检测框**之间的 **IoU (Intersection over Union) 距离**，构建成本矩阵。
   - **数据关联**: 使用**线性分配算法** (如匈牙利算法 `linearAssignment`) 解决该成本矩阵，为航迹找到最佳匹配的高分检测框。
   - 更新匹配项：
     - 成功匹配的航迹：使用卡尔曼滤波器的 `update()` 或 `reActivate()` 方法，融合检测框信息，校正其状态并更新轨迹。
     - 未匹配的航迹和检测框：分别存入 `remain_tracked_stracks` 和 `remain_det_stracks` 列表，用于后续处理。

   \* 第二次关联 (低分检测框):

   - **背景**: 这是 `BYTETrack` 的关键步骤，旨在处理遮挡。第一次关联后未匹配到的航迹，很可能是因为目标被遮挡导致检测分数降低。
   - **计算与关联**: 针对上一步中未匹配的航迹 (`remain_tracked_stracks`)，与**低分检测框** (`det_low_stracks`) 重复进行 IoU 距离计算和线性分配。
   - 更新与标记:
     - 成功匹配的航迹：同样进行 `update()` 或 `reActivate()`。
     - 第二次关联后仍然未匹配的航迹：将其状态标记为“丢失” (`markAsLost`)，并移入 `current_lost_stracks` 列表。这些航迹在后续几帧内若能重新被匹配上，则可被重新激活

3.  **航迹管理**：
   **航迹新生**: 对于在两次关联后都**未被匹配**的**高分检测框** (`remain_det_stracks` 中满足 `high_thresh_` 的部分)，认为它们是新出现的目标。为它们创建新的航迹，分配新的ID，并调用 `activate()` 方法进行初始化。**注意**：低分检测框永远不会用于初始化新航迹。

   **处理暂定航迹**: 代码还会处理 `non_active_stracks`（通常是刚诞生、尚未确认的航迹），尝试将它们与剩余的检测框匹配以进行确认。若持续无法匹配则标记为移除 (`markAsRemoved`)。

   **航迹消亡**: 遍历所有“丢失”状态的航迹 (`lost_stracks_`)，如果某个航迹丢失的时间超过了设定的最大时长 `max_time_lost_`，则将其彻底标记为“移除” (`markAsRemoved`)，因为它很可能已经离开了视野。

